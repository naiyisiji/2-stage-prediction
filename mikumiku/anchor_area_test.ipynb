{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_cluster import radius_graph\n",
    "from torch_cluster import radius\n",
    "from torch_geometric.data import Batch\n",
    "import matplotlib.pyplot as plt\n",
    "from layers import FourierEmbedding\n",
    "from utils.circle import minimum_enclosing_circle\n",
    "from modules.encoder import QCNetEncoder\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from layers.attention_layer import AttentionLayer\n",
    "from utils.geometry import angle_between_2d_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Area_Attn(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim_anchor_pts=2,\n",
    "                 head_num = 8,\n",
    "                 anchor_query_hidden_dim=128,\n",
    "                 anchor_area_query_num_freq_bands=64,\n",
    "                 anchor_area_max_pts_num = 400,\n",
    "                 dropout=0.1) -> None:\n",
    "        super(Area_Attn,self).__init__()\n",
    "        self.anchor_area_max_pts_num = anchor_area_max_pts_num\n",
    "        self.input_dim_anchor_pts = input_dim_anchor_pts\n",
    "        self.anchor_query_hidden_dim = anchor_query_hidden_dim\n",
    "        self.anchor_area_query_num_freq_bands = anchor_area_query_num_freq_bands\n",
    "        self.anchor_area_pos_embed = FourierEmbedding(input_dim=self.input_dim_anchor_pts, \n",
    "                                                       hidden_dim=self.anchor_query_hidden_dim, \n",
    "                                                       num_freq_bands=self.anchor_area_query_num_freq_bands)\n",
    "        self.attn = nn.MultiheadAttention(self.anchor_query_hidden_dim,head_num,dropout)\n",
    "        self.attn_postnorm = nn.LayerNorm(anchor_query_hidden_dim)\n",
    "        self.query_content_mlp = nn.Linear(anchor_query_hidden_dim,anchor_query_hidden_dim)\n",
    "        self.new_query_pos = nn.Linear(anchor_query_hidden_dim,input_dim_anchor_pts)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, \n",
    "                query_content:torch.Tensor, \n",
    "                query_pos:torch.Tensor, \n",
    "                agent_history_traj_feat:torch.Tensor,\n",
    "                ):\n",
    "        query_pos_shape = query_pos.shape\n",
    "        query_pos = query_pos.view(-1, query_pos.size(-1))\n",
    "        area_anchor_query_pos = self.anchor_area_pos_embed(continuous_inputs=query_pos,categorical_embs=None)\n",
    "        area_anchor_query_pos = area_anchor_query_pos.view(-1, self.anchor_area_max_pts_num, self.anchor_query_hidden_dim)\n",
    "        q_area_query = (area_anchor_query_pos +  query_content).permute(1,0,2)\n",
    "        k_agent_history_traj_feat = v_agent_history_traj_feat = agent_history_traj_feat.permute(1,0,2)\n",
    "\n",
    "        tmp,_ = self.attn(q_area_query, k_agent_history_traj_feat, v_agent_history_traj_feat)\n",
    "        tmp = tmp.permute(1,0,2)\n",
    "        query_content = self.attn_postnorm(query_content + tmp)\n",
    "        new_query_content = self.attn_postnorm(self.query_content_mlp(query_content) + query_content)\n",
    "        new_query_pos = query_pos.reshape(query_pos_shape) + self.relu(self.new_query_pos(new_query_content))\n",
    "\n",
    "        return  new_query_content, new_query_pos\n",
    "    \n",
    "class Area_anchor_self_attn(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim_anchor_pts=2,\n",
    "                 head_num = 8,\n",
    "                 anchor_query_hidden_dim=128,\n",
    "                 anchor_area_query_num_freq_bands=64,\n",
    "                 anchor_area_max_pts_num = 400,\n",
    "                 dropout=0.1) -> None:\n",
    "        super(Area_anchor_self_attn, self).__init__()\n",
    "        self.input_dim_anchor_pts = input_dim_anchor_pts\n",
    "        self.anchor_query_hidden_dim = anchor_query_hidden_dim\n",
    "        self.anchor_area_max_pts_num = anchor_area_max_pts_num\n",
    "        self.anchor_area_query_num_freq_bands = anchor_area_query_num_freq_bands\n",
    "        self.anchor_area_pos_embed = FourierEmbedding(input_dim=self.input_dim_anchor_pts, \n",
    "                                                       hidden_dim=self.anchor_query_hidden_dim, \n",
    "                                                       num_freq_bands=self.anchor_area_query_num_freq_bands)\n",
    "\n",
    "        self.pos_embed_mlp = nn.Linear(anchor_query_hidden_dim,anchor_query_hidden_dim)\n",
    "        self.self_attn = nn.MultiheadAttention(self.anchor_query_hidden_dim,head_num,dropout)\n",
    "        self.attn_postnorm = nn.LayerNorm(anchor_query_hidden_dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,\n",
    "                query_content:torch.Tensor, \n",
    "                query_pos:torch.Tensor, ):   \n",
    "        query_pos_shape = query_pos.shape\n",
    "        query_pos_embed = query_pos.view(-1, query_pos.size(-1)) \n",
    "        query_pos_embed = self.anchor_area_pos_embed(query_pos_embed)\n",
    "        query_pos_embed = query_pos_embed.view(query_pos_shape[0], query_pos_shape[1], -1)\n",
    "        query_pos_embed = self.pos_embed_mlp(query_pos_embed)\n",
    "        query_pos_embed = self.relu(query_pos_embed)\n",
    "        \n",
    "        q = k = query_content + query_pos_embed\n",
    "        v = query_content\n",
    "        tmp,_  = self.self_attn(q.permute(1,0,2),k.permute(1,0,2),v.permute(1,0,2))\n",
    "        tmp = tmp.permute(1,0,2)\n",
    "        new_query_content = self.attn_postnorm(tmp + query_content) \n",
    "        new_query_pos = query_pos\n",
    "        return new_query_content, new_query_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Area_anchor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim=2,                                     # setting the geo dim in prediction\n",
    "                 agent_feat_dim=4,                          # setting the num of agent input feature\n",
    "                 self_attn_num_layers = 1,                  # setting the num of agent_self_attn\n",
    "                 agent_query_hidden_dim=128,                # setting the num of query_hidden_dim used for anchor_query\n",
    "                 history_steps=50,\n",
    "                 time_span = None,\n",
    "                 input_dim_anchor_pts=2,                    # setting the num of dim used for query_pos\n",
    "                 anchor_query_hidden_dim=128,               # used like query_pos hidden dim \n",
    "                 anchor_query_num_freq_bands=64,            # used for query_pos fouri embed\n",
    "                 anchor_area_query_num_freq_bands=64,       # used for agent_traj embed\n",
    "                 agent2map_pts_max_length=400,              # setting the max num of anchor pts\n",
    "                 agent_self_attn_num_head=8,                # setting agent_self_attn TR model's head\n",
    "                 agent_self_attn_head_dim=16,               # setting agent_self_attn TR model's head dim hidden=head_num*head_dim\n",
    "                 agent_self_attn_dropout=0.1,\n",
    "                 agent_self_attn_fouri_embed=64,\n",
    "                 query_pts_num=400\n",
    "                 ) -> None:      \n",
    "        super(Area_anchor, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.query_pts_num = query_pts_num\n",
    "        self.feat_dim = agent_query_hidden_dim\n",
    "        self.self_attn_num_layers = self_attn_num_layers\n",
    "        self.history_steps = history_steps\n",
    "        self.agent2map_pts_max_length = agent2map_pts_max_length\n",
    "        self.time_span = time_span if time_span is not None else history_steps\n",
    "        self.query_pos = FourierEmbedding(input_dim=input_dim_anchor_pts, \n",
    "                                          hidden_dim=anchor_query_hidden_dim, \n",
    "                                          num_freq_bands=anchor_query_num_freq_bands)\n",
    "        self.agent_self_pos_embed = FourierEmbedding(input_dim=dim, \n",
    "                                        hidden_dim=agent_query_hidden_dim, \n",
    "                                        num_freq_bands=agent_self_attn_fouri_embed)\n",
    "\n",
    "        self.query_embed = nn.Parameter(torch.rand(self.agent2map_pts_max_length, self.feat_dim))\n",
    "        self.type_agent_history_traj_emb =  nn.Embedding(10, agent_query_hidden_dim)\n",
    "        self.agent_history_traj_emb = FourierEmbedding(input_dim=agent_feat_dim, hidden_dim=agent_query_hidden_dim, num_freq_bands=anchor_area_query_num_freq_bands)\n",
    "\n",
    "        # setting agent_traj_self_attn\n",
    "        self.self_attn_num_layers = self_attn_num_layers\n",
    "        self.agent_traj_self_attn = nn.ModuleList(\n",
    "            [AttentionLayer(hidden_dim=agent_query_hidden_dim, \n",
    "                            num_heads=agent_self_attn_num_head, \n",
    "                            head_dim=agent_self_attn_head_dim, \n",
    "                            dropout=agent_self_attn_dropout,\n",
    "                            bipartite=False, has_pos_emb=True) for _ in range(self_attn_num_layers)])\n",
    "        self.area_attn = Area_Attn(head_num=agent_self_attn_num_head)\n",
    "        self.area_anchor_self_attn = Area_anchor_self_attn()\n",
    "\n",
    "    def forward(self,data):\n",
    "        init_anchor_pts = self.init_anchor_area(data, \n",
    "                                                self.history_steps, \n",
    "                                                self.dim, \n",
    "                                                self.agent2map_pts_max_length,\n",
    "                                                relative_pos=False)\n",
    "        init_area_anchor_query_content = self.query_embed.unsqueeze(0).repeat(data['agent']['num_nodes'],1,1)\n",
    "\n",
    "        # ==============================agent_history_traj self_attn============================== #\n",
    "        pos_a = data['agent']['position'][:, :self.history_steps, :self.dim].contiguous()\n",
    "        motion_vector_a = torch.cat([pos_a.new_zeros(data['agent']['num_nodes'], 1, self.dim),pos_a[:, 1:] - pos_a[:, :-1]], dim=1)\n",
    "        head_a = data['agent']['heading'][:, :self.history_steps].contiguous()\n",
    "        head_vector_a = torch.stack([head_a.cos(), head_a.sin()], dim=-1)\n",
    "        vel = data['agent']['velocity'][:, :self.history_steps, :self.dim].contiguous()\n",
    "        agent_traj_feat = torch.stack( #agent_traj_feat shape: [agent_num, self.history_steps, self.dim]\n",
    "            [torch.norm(motion_vector_a[:, :, :2], p=2, dim=-1),\n",
    "                angle_between_2d_vectors(ctr_vector=head_vector_a, nbr_vector=motion_vector_a[:, :, :2]),\n",
    "                torch.norm(vel[:, :, :2], p=2, dim=-1),\n",
    "                angle_between_2d_vectors(ctr_vector=head_vector_a, nbr_vector=vel[:, :, :2])], dim=-1)  \n",
    "        categorical_embs = [self.type_agent_history_traj_emb(data['agent']['type'].long()).repeat_interleave(repeats=self.history_steps,dim=0)]\n",
    "        agent_traj_feat = self.agent_history_traj_emb(continuous_inputs=agent_traj_feat.view(-1, agent_traj_feat.size(-1)), categorical_embs=categorical_embs)\n",
    "        agent_traj_feat = agent_traj_feat.view(-1, self.history_steps, self.feat_dim) # agent_traj_feat shape [agent_num,self.history_steps,self.feat_dim]\n",
    "        \n",
    "        # set timestep index\n",
    "        mask = data['agent']['valid_mask'][:, :self.history_steps].contiguous()\n",
    "        mask_t = mask.unsqueeze(2) & mask.unsqueeze(1)\n",
    "        edge_index_t = dense_to_sparse(mask_t)[0]\n",
    "        edge_index_t = edge_index_t[:, edge_index_t[1] > edge_index_t[0]]\n",
    "        edge_index_t = edge_index_t[:, edge_index_t[1] - edge_index_t[0] <= self.time_span]\n",
    "        \n",
    "        # set pos_embed\n",
    "        pos_t = pos_a.reshape(-1, self.dim) \n",
    "        rel_pos_t = pos_t[edge_index_t[0]] - pos_t[edge_index_t[1]]\n",
    "        r_t = rel_pos_t[:, :2]\n",
    "        r_t = self.agent_self_pos_embed(continuous_inputs=r_t, categorical_embs=None)\n",
    "        for i in range(self.self_attn_num_layers):\n",
    "            agent_traj_feat = agent_traj_feat.reshape(-1, self.feat_dim)\n",
    "            agent_traj_feat = self.agent_traj_self_attn[i](agent_traj_feat, r_t, edge_index_t)\n",
    "        \n",
    "        agent_traj_feat = agent_traj_feat.reshape(-1,self.history_steps,self.feat_dim)\n",
    "        # ======================================================================================== #\n",
    "\n",
    "        # ====================================choose pred traj==================================== #\n",
    "        pred_mask = data['agent']['predict_mask'].any(dim=-1, keepdim=True)\n",
    "        init_area_anchor_query_content_need_pred = init_area_anchor_query_content[pred_mask.squeeze()]\n",
    "        agent_traj_feat_need_pred = agent_traj_feat[pred_mask.squeeze()]\n",
    "        init_anchor_pts_need_pred = init_anchor_pts[pred_mask.squeeze()]\n",
    "        # ======================================================================================== #\n",
    "        init_area_anchor_query_content_need_pred,init_anchor_pts_need_pred= self.area_anchor_self_attn(init_area_anchor_query_content_need_pred,\n",
    "                                                                                                       init_anchor_pts_need_pred)\n",
    "        _,new_query_pos = self.area_attn(query_content = init_area_anchor_query_content_need_pred,\n",
    "                       query_pos = init_anchor_pts_need_pred,\n",
    "                       agent_history_traj_feat = agent_traj_feat_need_pred)\n",
    "        return new_query_pos, init_anchor_pts\n",
    "\n",
    "    def init_anchor_area(self, data, history_steps, dim, query_pts_num=400, relative_pos=True):\n",
    "        device = data['agent']['predict_mask'].device\n",
    "        pred_mask = data['agent']['predict_mask'].any(dim=-1, keepdim=True)\n",
    "        init_anchor_list = []\n",
    "        \n",
    "        for each_agent_idx in range(data['agent']['num_nodes']):\n",
    "            if not pred_mask[each_agent_idx]:\n",
    "                init_anchor_list.append(torch.zeros(query_pts_num, dim, device=device))\n",
    "                continue\n",
    "            \n",
    "            ref = data['agent']['position'][each_agent_idx, history_steps, :dim].to(device)\n",
    "            \n",
    "            valid_history_steps = (data['agent']['position'][each_agent_idx, :history_steps, :dim].permute(1, 0) * \n",
    "                                data['agent']['valid_mask'][each_agent_idx, :history_steps]).permute(1, 0)\n",
    "            valid_history_steps = valid_history_steps - ref\n",
    "            proj_pred_pts = -valid_history_steps[data['agent']['valid_mask'][each_agent_idx, :history_steps]]\n",
    "            \n",
    "            try:\n",
    "                tmp = proj_pred_pts.repeat(query_pts_num // proj_pred_pts.shape[0], 1).to(device)\n",
    "                _, r = minimum_enclosing_circle(valid_history_steps[data['agent']['valid_mask'][each_agent_idx, :history_steps], :])\n",
    "                tmp = (torch.cat((tmp, proj_pred_pts[:query_pts_num % proj_pred_pts.shape[0]]), dim=0) + \n",
    "                    torch.randn(query_pts_num, dim, device=device) * r * 0.1).to(device)\n",
    "            except:\n",
    "                r =torch.tensor([0.01]).to(device)\n",
    "                tmp = torch.randn(query_pts_num,dim).to(device) * r\n",
    "            \n",
    "            if not relative_pos:\n",
    "                tmp = (tmp + ref).to(device)\n",
    "            init_anchor_list.append(tmp)\n",
    "        \n",
    "        init_anchor_pts = torch.stack(init_anchor_list, dim=0)\n",
    "        return init_anchor_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "def hungarian_hausdorff_loss(pred_points, gt_points):\n",
    "    num_pred_points = pred_points.size(0)\n",
    "    num_gt_points = gt_points.size(0)\n",
    "    \n",
    "    if num_pred_points > num_gt_points:\n",
    "        cost_matrix = torch.cdist(pred_points, gt_points, p=2).detach().cpu().numpy()\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        selected_pred_points = pred_points[row_ind]\n",
    "    else:\n",
    "        cost_matrix = torch.cdist(gt_points, pred_points, p=2).detach().cpu().numpy()\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "        selected_pred_points = gt_points[col_ind]\n",
    "\n",
    "    selected_pred_points = torch.tensor(selected_pred_points, requires_grad=True).to(pred_points.device)\n",
    "    \n",
    "    dists_A_to_B = torch.cdist(selected_pred_points, gt_points, p=2)\n",
    "    min_dists_A_to_B = torch.min(dists_A_to_B, dim=1)[0]\n",
    "    min_dists_B_to_A = torch.min(dists_A_to_B, dim=0)[0]\n",
    "    hausdorff_dist = torch.max(torch.max(min_dists_A_to_B), torch.max(min_dists_B_to_A))\n",
    "    \n",
    "    return hausdorff_dist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, lambda_area=1.0):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.lambda_area = lambda_area\n",
    "\n",
    "    def forward(self, points_A, points_B):\n",
    "        distribution_loss = self.compute_distribution_loss(points_A, points_B)\n",
    "        area_loss = self.compute_area_loss(points_A)\n",
    "        total_loss = distribution_loss + self.lambda_area * area_loss * 0.1\n",
    "        return total_loss\n",
    "\n",
    "    def compute_distribution_loss(self, points_A, points_B):\n",
    "        dist_matrix = torch.cdist(points_A, points_B)\n",
    "        min_dist, _ = dist_matrix.min(dim=1)\n",
    "        return min_dist.mean()\n",
    "\n",
    "    def compute_area_loss(self, points_A):\n",
    "        points_A = points_A.detach().cpu().numpy()\n",
    "        if len(points_A) < 3:  # ConvexHull requires at least 3 points\n",
    "            return torch.tensor(0.0)\n",
    "        hull = ConvexHull(points_A)\n",
    "        return torch.tensor(hull.volume, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "118\n",
      "torch.Size([82, 400, 2])\n",
      "1\n",
      "57\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mQhullError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 29\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43meach_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43meach_gt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# print(each_pred)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\anaconda3\\envs\\pytorch_py3_9\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mCustomLoss.forward\u001b[1;34m(self, points_A, points_B)\u001b[0m\n\u001b[0;32m     39\u001b[0m distribution_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_distribution_loss(points_A, points_B)\n\u001b[1;32m---> 40\u001b[0m area_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_area_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints_A\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m distribution_loss \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_area \u001b[38;5;241m*\u001b[39m area_loss \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36mCustomLoss.compute_area_loss\u001b[1;34m(self, points_A)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m hull \u001b[38;5;241m=\u001b[39m \u001b[43mConvexHull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints_A\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(hull\u001b[38;5;241m.\u001b[39mvolume, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m_qhull.pyx:2448\u001b[0m, in \u001b[0;36mscipy.spatial._qhull.ConvexHull.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_qhull.pyx:358\u001b[0m, in \u001b[0;36mscipy.spatial._qhull._Qhull.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mQhullError\u001b[0m: QH6421 qhull internal error (qh_maxsimplex): qh.MAXwidth required for qh_maxsimplex.  Used to estimate determinate\n\nWhile executing:  | qhull i Qt\nOptions selected for Qhull 2019.1.r 2019/06/21:\n  run-id 161674014  incidence  Qtriangulate  _pre-merge  _zero-centrum\n  _max-width  0  Error-roundoff 4.5e-12  _one-merge 2.2e-11\n  _near-inside 1.1e-10  Visible-distance 8.9e-12  U-max-coplanar 8.9e-12\n  Width-outside 1.8e-11  _wide-facet 5.4e-11  _maxoutside 2.7e-11\n\nA Qhull internal error has occurred.  Please send the input and output to\nqhull_bug@qhull.org. If you can duplicate the error with logging ('T4z'), please\ninclude the log file.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(iii)\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m---> 36\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124min\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m lalala \u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mValueError\u001b[0m: in"
     ]
    }
   ],
   "source": [
    "from dataset_prepare.argoverse_v2_dataset import ArgoverseV2Dataset\n",
    "from torch_geometric.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "dataset = ArgoverseV2Dataset('D:\\\\argoverse2', 'train', None, None, None)\n",
    "loader = DataLoader(dataset,batch_size=4,shuffle=False)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "testqc = Area_anchor().to(device)\n",
    "optimizer = torch.optim.SGD(testqc.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "criterion = CustomLoss(lambda_area=0.1)\n",
    "epoch = 40\n",
    "\n",
    "min_loss = np.inf\n",
    "best_model_path = 'C:\\\\Users\\\\Lenovo\\\\OneDrive - City University of Hong Kong - Student\\\\Desktop\\\\mikumiku\\\\mikumiku\\\\best_model.pth'\n",
    "\n",
    "for ii in range(epoch):\n",
    "    print(ii)\n",
    "    \n",
    "    for data,iii in zip(loader,range(len(loader))):\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        pred,init_raw = testqc(data = data.to(device))\n",
    "        pred_mask = data['agent']['predict_mask'].any(dim=-1, keepdim=True).squeeze()\n",
    "        gt = data['agent']['position'][pred_mask,:,:]\n",
    "        for each_pred,each_gt,i in zip(pred,gt,range(gt.shape[0])):\n",
    "            each_gt = each_gt[50:,:][data['agent']['predict_mask'][pred_mask][i,50:],:2]\n",
    "            try:\n",
    "                loss += criterion(each_pred,each_gt)\n",
    "            except:\n",
    "                # print(each_pred)\n",
    "                print(lalala)\n",
    "                print(pred.shape)\n",
    "                print(iii)\n",
    "                print(i)\n",
    "                raise ValueError('in')\n",
    "        lalala = pred.shape[0]\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ====================================save best model param==================================== #\n",
    "        if loss.item() < min_loss:\n",
    "            min_loss = loss.item()\n",
    "            torch.save(testqc.state_dict(), best_model_path)\n",
    "    print(loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset_prepare.argoverse_v2_dataset import ArgoverseV2Dataset\n",
    "from torch_geometric.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "dataset = ArgoverseV2Dataset('D:\\\\argoverse2', 'train', None, None, None)\n",
    "loader = DataLoader(dataset,batch_size=4)\n",
    "device = torch.device('cuda')\n",
    "\n",
    "testqc = Area_anchor().to(device)\n",
    "\n",
    "epoch = 40\n",
    "min_loss = np.inf\n",
    "best_model_path = 'C:\\\\Users\\\\Lenovo\\\\OneDrive - City University of Hong Kong - Student\\\\Desktop\\\\mikumiku\\\\mikumiku\\\\best_model.pth'\n",
    "\n",
    "testqc.load_state_dict(torch.load(best_model_path))\n",
    "testqc.eval()\n",
    "\n",
    "for data, test_used_i in zip(loader,range(loader.__len__())):\n",
    "    test_used_loader = 1\n",
    "\n",
    "    if test_used_i != test_used_loader:\n",
    "        continue\n",
    "    pred,_ = testqc(data = data.to(device))\n",
    "    pred_mask = data['agent']['predict_mask'].any(dim=-1, keepdim=True).squeeze()\n",
    "    gt = data['agent']['position'][pred_mask,:,:]\n",
    "    gt_train = data['agent']['position'][pred_mask,:,:]\n",
    "    train_valid_mask = data['agent']['valid_mask'][pred_mask,:]\n",
    "\n",
    "    for each_pred,each_gt,i in zip(pred,gt,range(gt.shape[0])):\n",
    "        test_num = 38\n",
    "        if i != test_num:\n",
    "            continue\n",
    "        each_gt = each_gt[50:,:][data['agent']['predict_mask'][pred_mask][i,50:],:2]\n",
    "        each_gt_train = gt_train[i,:50][train_valid_mask[i,:50],:2]\n",
    "        each_gt_train = each_gt_train.detach().cpu().numpy()\n",
    "        each_gt = each_gt.detach().cpu().numpy()\n",
    "        each_pred = each_pred.detach().cpu().numpy()\n",
    "        plt.scatter(each_pred[:,0],each_pred[:,1], c='r')\n",
    "        plt.scatter(each_gt[:,0],each_gt[:,1], c='g')\n",
    "        #print(gt[test_num])\n",
    "        #print(gt[test_num].shape)\n",
    "        plt.scatter(each_gt_train[:,0],each_gt_train[:,1], c='b')\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_py3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
